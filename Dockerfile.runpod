# RunPod Serverless Dockerfile for Crawl4AI MCP Server
# Optimized for CPU-only serverless workloads

FROM python:3.11-slim

# Set working directory
WORKDIR /

# Install system dependencies for Playwright and file processing
RUN apt-get update && apt-get install -y \
    # Playwright browser dependencies
    libnss3 \
    libnspr4 \
    libasound2 \
    libatk-bridge2.0-0 \
    libdrm2 \
    libgtk-3-0 \
    libgbm1 \
    libxss1 \
    libgconf-2-4 \
    libxtst6 \
    libxrandr2 \
    libpangocairo-1.0-0 \
    libatk1.0-0 \
    libcairo-gobject2 \
    libgtk-3-0 \
    libgdk-pixbuf2.0-0 \
    # Additional utilities
    curl \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
# First install runpod for serverless functionality
RUN pip install --no-cache-dir runpod

# Copy requirements and install project dependencies
COPY requirements.txt .
COPY requirements-runpod.txt .
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install --no-cache-dir -r requirements-runpod.txt

# Install Playwright browsers (only Chromium for efficiency)
RUN playwright install chromium

# Copy the entire project
COPY . .

# Copy RunPod handler
COPY runpod_handler.py /

# Create test input file for local testing
RUN echo '{"input": {"operation": "crawl_url", "params": {"url": "https://httpbin.org/html", "generate_markdown": true}}}' > test_input.json

# Set environment variables for RunPod
ENV PYTHONPATH=/
ENV PYTHONUNBUFFERED=1
ENV FASTMCP_LOG_LEVEL=INFO

# Health check (optional for RunPod)
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "from crawl4ai_mcp.server import mcp; print('Health check passed')" || exit 1

# Start the RunPod serverless worker
CMD ["python", "-u", "runpod_handler.py"]